{
  "name": "FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference",
  "description": "Dynamically adjusts sparse attention patterns and computational budget in real-time to meet the specific requirements of each input and attention head.",
  "method_type": [
    "Continual Learning"
  ],
  "gpus_required": "Medium",
  "training_speed": "Fast",
  "source": "https://arxiv.org/abs/2502.20766",
  "code_url": "https://github.com/bytedance/FlexPrefill",
  "open_source": false,
  "intended_use": [
    "Context-Aware Sparse Inference"
  ]
}
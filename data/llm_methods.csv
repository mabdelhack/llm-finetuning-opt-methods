name,description,method_type,source,code_url,open_source,gpus_required,training_speed,intended_use
Supervised Fine-Tuning (SFT),Involves training a pre-trained LLM on a labeled dataset to adapt it to specific tasks or domains.,Fine-Tuning,https://arxiv.org/abs/2412.13337,https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py,Yes,Varies,Moderate,Task Adaptation
Reward Modeling,"Involves training a model to predict human preferences or rewards, often used in reinforcement learning to guide the behavior of LLMs.",Alignment,https://arxiv.org/abs/2502.10325,https://github.com/sanjibanc/agent_prm,Yes,Varies,Moderate,Preference Prediction
Proximal Policy Optimization (PPO),A reinforcement learning algorithm that alternates between sampling data through interaction with the environment and optimizing a surrogate objective function using stochastic gradient ascent.,Alignment,https://arxiv.org/abs/1707.06347,https://github.com/nikhilbarhate99/PPO-PyTorch?tab=readme-ov-file,Yes,High,Slow,Policy Optimization
Direct Preference Optimization (DPO),"An algorithm that directly optimizes a language model to adhere to human preferences without explicit reward modeling or reinforcement learning, simplifying the alignment process.",Alignment,https://arxiv.org/abs/2305.18290,https://github.com/eric-mitchell/direct-preference-optimization,Yes,Varies,Moderate,Preference Alignment
Optimistic model Rollouts for Pessimistic offline policy Optimization (ORPO),"A value-based algorithm for KL-regularized reinforcement learning that guides the reference policy using the optimal regularized Q function, aiming for optimal policy learning in LLM post-training.",Alignment,https://arxiv.org/abs/2401.05899,N/A,N/A,High,Slow,Policy Optimization
Low-Rank Adaptation (LoRA),"Introduces trainable low-rank matrices into each layer of a pre-trained model, allowing efficient fine-tuning with significantly fewer parameters.",PEFT,https://arxiv.org/abs/2106.09685,https://github.com/microsoft/LoRA,Yes,Low,Fast,Task Adaptation
Singular Value Fine-Tuning (SVF),"Decomposes model parameters using Singular Value Decomposition (SVD) and fine-tunes only the singular values, keeping other components frozen, to adapt models to new tasks with minimal risk of overfitting.",PEFT,https://arxiv.org/abs/2206.06122,https://github.com/syp2ysy/SVF,Yes,Low,Fast,Few-Shot Learning
Parameter-Efficient Fine-Tuning (PEFT),"A broad class of methods that fine-tune pre-trained models by updating a small subset of parameters, reducing computational costs while maintaining performance. Examples include LoRA, SVF, and adapters.",PEFT,https://arxiv.org/abs/2403.08484,N/A,N/A,Varies,Varies,Task Adaptation
Category-Wise Fine-Tuning (CFT),"Fine-tunes models by focusing on individual categories, using known labels to adjust model predictions and reduce inaccuracies caused by incorrect pseudo-labels.",Fine-Tuning,https://arxiv.org/abs/2401.16991,https://github.com/maxium0526/category-wise-fine-tuning,Yes,Varies,Moderate,Classification Tasks
Sequential Fine-Tuning,Involves fine-tuning models on a sequence of tasks or instructions to improve performance on complex tasks by leveraging knowledge from previous tasks.,Fine-Tuning,https://arxiv.org/abs/2402.18905,N/A,Yes,Varies,Moderate,Complex Task Learning
Gradient-Guided Annealing,"Aims to improve domain generalization by iteratively annealing model parameters in the early stages of training to align gradients across domains, reducing domain conflicts.",Optimization,https://arxiv.org/abs/2502.20162,https://github.com/aristotelisballas/GGA,Yes,Varies,Moderate,Domain Generalization
Multiscale Byte Language Model (MBLM),"Utilizes a hierarchical architecture in the decoder stack to handle long context windows efficiently, allowing training with extensive context on limited hardware resources.",Architecture,https://arxiv.org/abs/2502.14553,https://github.com/ai4sd/multiscale-byte-lm,Yes,High,Slow,Long Context Processing
Modular LoRA,"Extends LoRA by creating a library of LoRA adapters for different tasks, enabling modular and reusable components for efficient multi-task learning.",PEFT,https://arxiv.org/abs/2405.11157,N/A,N/A,Low,Fast,Multi-Task Learning
Multi-Model Stochastic Particle-Based Variational Bayesian Inference,"A framework capable of exploring multiple high-dimensional parameter spaces for joint model selection and parameter estimation, addressing challenges in complex estimation problems.",Optimization,https://arxiv.org/abs/2502.20690,N/A,N/A,High,Slow,Model Selection and Parameter Estimation
Path Scheduling,"A method that integrates LLMs into path planning algorithms to enhance efficiency by leveraging global reasoning capabilities, effectively reducing the number of visited states.",Optimization,https://arxiv.org/abs/2407.02511,https://github.com/SilinMeng0510/llm-astar,Yes,Varies,Moderate,Path Planning
Factuality-Aware Fine-Tuning,A technique aimed at reducing hallucinations in LLMs by identifying and mitigating factors that lead to factual inaccuracies during both supervised fine-tuning and reinforcement learning alignment steps.,Fine-Tuning,https://arxiv.org/abs/2405.01525,N/A,N/A,Varies,Moderate,Improving Response Factuality
HydraLoRA,An Asymmetric LoRA Architecture for Efficient Fine-Tuning,Fine-Tuning,https://openreview.net/forum?id=qEpi8uWX3N,https://github.com/Clin0212/HydraLoRA/tree/main/MLLM-HydraLoRA,Yes,High,Slow,Multi-Modal Generation
Cross-Modal Coordination,"Techniques that enable LLMs to reason across different data types (modalities), enhancing tasks like visual question answering and image captioning by integrating cross-modal projections.",Multi-Modal Reasoning,https://arxiv.org/html/2409.18996v1,https://github.com/ZuyiZhou/Awesome-Cross-modal-Reasoning-with-LLMs,Yes,High,Slow,Cross-Modal Reasoning
Instruction Fine-Tuning,Fine-tuning LLMs on datasets consisting of instructional prompts and corresponding outputs to improve the model's ability to follow instructions across various tasks.,Fine-Tuning,https://arxiv.org/abs/2109.01652,https://github.com/google-research/flan,Yes,Varies,Moderate,Task Adaptation
Dialogue Fine-Tuning,Fine-tuning LLMs on conversational datasets to enhance their ability to maintain context and coherence across multiple exchanges in dialogue systems.,Fine-Tuning,https://arxiv.org/abs/2109.10126,https://github.com/togethercomputer/together-cookbook/blob/main/Multiturn_Conversation_Finetuning.ipynb,Yes,Varies,Moderate,Conversational AI
Chain-of-Thought (CoT) Fine-Tuning,"Fine-tuning LLMs using datasets that incorporate reasoning steps, enabling models to generate more logical and structured responses by mimicking human-like reasoning processes.",Fine-Tuning,https://arxiv.org/abs/2305.14045,https://github.com/kaistAI/CoT-Collection,Yes,Varies,Moderate,Enhanced Reasoning
Domain-Specific Fine-Tuning,"Adapting pre-trained LLMs to specific domains by fine-tuning on domain-relevant datasets, improving performance on tasks within that domain.",Fine-Tuning,https://arxiv.org/abs/2401.08406,N/A,N/A,Varies,Moderate,Domain Adaptation
Distillation-Based Fine-Tuning,"Training smaller models to replicate the behavior of larger LLMs, achieving similar performance with reduced computational requirements through knowledge distillation techniques.",Optimization,https://snorkel.ai/blog/llm-distillation-demystified-a-complete-guide/,https://huggingface.co/docs/optimum/en/index,Yes,Low,Fast,Model Compression
QLoRA,"Efficient fine-tuning approach that reduces memory usage by backpropagating gradients through a frozen, 4-bit quantized pretrained language model into Low-Rank Adapters (LoRA), enabling fine-tuning of large models on limited hardware without performance loss.",Quantization,https://arxiv.org/abs/2305.14314,https://github.com/artidoro/qlora,Yes,Low,Fast,Resource-Constrained Fine-Tuning
GPTQ,"A post-training quantization method that uses second-order information to perform accurate and efficient quantization of GPT models, enabling execution of large models on a single GPU with minimal accuracy degradation.",Quantization,https://arxiv.org/abs/2210.17323,https://github.com/IST-DASLab/gptq,Yes,Low,Fast,Model Compression
SparseGPT,"A one-shot pruning method that efficiently reduces the size of massive language models by removing unimportant weights, achieving significant sparsity with negligible impact on performance.",Pruning,https://arxiv.org/abs/2301.00774,https://github.com/IST-DASLab/sparsegpt,Yes,Low,Fast,Model Compression
AdaLoRA,"An adaptive budget allocation method for parameter-efficient fine-tuning that dynamically assigns parameter budgets among weight matrices based on their importance, enhancing fine-tuning performance while maintaining efficiency.",PEFT,https://arxiv.org/abs/2303.10512,https://github.com/QingruZhang/AdaLoRA,Yes,Low,Fast,Task Adaptation
P-Tuning v2,"An optimized prompt tuning method that enables prompt tuning to match the performance of full model fine-tuning across various model scales and tasks, with only 0.1%-3% of parameters tuned.",Prompt Tuning,https://arxiv.org/abs/2110.07602,https://github.com/THUDM/P-tuning-v2,Yes,Low,Fast,Task Adaptation
Tree-of-Thoughts (ToT),"A framework that enhances problem-solving capabilities of LLMs by allowing deliberate decision-making through exploration of multiple reasoning paths, enabling backtracking and strategic planning.",Reasoning,https://arxiv.org/abs/2305.10601,https://github.com/princeton-nlp/tree-of-thought-llm,Yes,Varies,Moderate,Complex Problem Solving
Graph of Thoughts (GoT),"A framework that models information generated by LLMs as an arbitrary graph, where units of information (""thoughts"") are vertices, and edges correspond to dependencies, facilitating complex problem-solving.",Reasoning,https://arxiv.org/abs/2308.09687,https://github.com/spcl/graph-of-thoughts,Yes,Varies,Moderate,Complex Problem Solving
Confidence-Based Sampling,An uncertainty quantification framework that combines direct confidence elicitation and sample-based consistency methods to provide better calibration for NLP misinformation mitigation solutions.,Uncertainty Estimation,https://arxiv.org/abs/2401.08694,N/A,N/A,Varies,Moderate,Misinformation Mitigation
Search Against Verifiers,"A post-training paradigm that leverages automated verifiers to perform verification tasks and deliver meaningful feedback to foundation models, enhancing their performance and reliability.",Post-Training,https://arxiv.org/abs/2411.11504,https://github.com/icip-cas/Verifier-Engineering,Yes,Varies,Moderate,Model Alignment
Monte Carlo Tree Search (MCTS),A decision-making algorithm that balances exploration and exploitation by performing random sampling in the form of simulations and storing statistics of actions to make educated choices in each iteration.,,https://arxiv.org/abs/2305.14078,https://github.com/1989Ryan/llm-mcts,Yes,Varies,Moderate,Sequential Decision Problems
Chain-of-Action-Thought Reasoning,"An approach that enhances the reasoning capabilities of LLMs through an iterative preference learning process inspired by strategies employed by AlphaZero, utilizing MCTS to iteratively collect preference data.",Reasoning,https://arxiv.org/abs/2502.02508,https://github.com/satori-reasoning/Satori,Yes,Varies,Moderate,Enhanced Reasoning
Precision Optimization,"A method that optimizes the precision-recall trade-off in generative modeling by utilizing divergence optimization techniques, applicable to models like GANs and normalizing flows.",Optimization,https://arxiv.org/abs/2305.18910,https://github.com/AlexVerine/RejectBigGan,Yes,Varies,Moderate,Generative Modeling
Post-Training Techniques,"Various methodologies applied after the initial training of LLMs to refine their performance, address challenges like catastrophic forgetting, and enhance capabilities such as reasoning and alignment.",Post-Training,https://arxiv.org/abs/2502.21321,https://github.com/mbzuai-oryx/Awesome-LLM-Post-training,Yes,Varies,Moderate,Model Refinement
Computational Performance Optimization,Techniques aimed at improving the efficiency and,Optimization,https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization,https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization,Yes,Varies,Fast,Efficient Deployment
Stochastic Rounding and BF16,"Techniques that improve computational efficiency and performance of LLMs by using stochastic rounding and Brain Floating Point (BF16) precision, reducing memory usage and accelerating training without significant loss of accuracy.",Optimization,https://arxiv.org/abs/2502.20566,N/A,N/A,Low,Fast,Efficient Training and Inference
PEARL: Learning to Paraphrase for Alignment with LLM Preference,"Methods that enhance LLM performance by incorporating phrasal paraphrase relations, improving the model's ability to understand and generate diverse expressions of the same meaning.",Optimization,https://aclanthology.org/2024.findings-emnlp.134/,https://github.com/630bdd/PEARL,Yes,Varies,Moderate,Enhanced Language Understanding
Hyperparameter Tuning,"The process of optimizing the hyperparameters of LLMs to achieve better performance, involving techniques like grid search, random search, and Bayesian optimization.",Optimization,https://symbl.ai/developers/blog/a-guide-to-llm-hyperparameters/,N/A,N/A,Varies,Moderate,Model Optimization
Low-Bit Quantization,"Techniques that reduce the precision of model weights and activations to lower bit-widths (e.g., 8-bit or 4-bit), decreasing memory usage and computational requirements while maintaining acceptable performance.",Quantization,https://arxiv.org/abs/2411.17691,https://huggingface.co/Xu-Ouyang,Yes,Low,Fast,Efficient Deployment
Sparse Implementations,"Methods that leverage sparsity in LLMs to reduce the number of active parameters during computation, enhancing efficiency without significantly compromising performance.",Optimization,https://arxiv.org/html/2407.10969v2,N/A,N/A,Low,Fast,Efficient Deployment
Zeroth-Order (ZO) Optimization,"Optimization techniques that estimate gradients using function evaluations, useful when gradient information is unavailable or expensive to compute, applicable in fine-tuning LLMs.",Optimization,https://arxiv.org/abs/2402.11592,https://github.com/ZO-Bench/ZO-LLM,Yes,Varies,Moderate,Model Optimization
Long-Sequence Inference Optimization,"Techniques designed to improve the efficiency and accuracy of LLMs when processing long input sequences, addressing challenges like context fragmentation and memory limitations.",Optimization,https://arxiv.org/abs/2309.12307,https://github.com/dvlab-research/LongLoRA,Yes,High,Slow,Long-Context Processing
Optimizations in LLM Scheduling and Resource Management,"Approaches that optimize the allocation and utilization of computational resources during the training and deployment of LLMs, enhancing efficiency and reducing costs.",Optimization,https://arxiv.org/abs/2502.20576,https://github.com/agiresearch/ECCOS,Yes,Varies,Moderate,Efficient Training and Deployment
Alignment Loss and Bidirectional Negative Feedback (BNF),"Techniques that incorporate alignment loss functions and bidirectional negative feedback mechanisms to fine-tune LLMs, improving their alignment with human preferences and reducing undesirable behaviors.",Fine-Tuning,https://arxiv.org/abs/2410.04834,N/A,N/A,Varies,Moderate,Model Alignment
Learning-on-Model Framework,Learns the parameters of the heterogeneous sub-models via convolutional compression,Post-Training,https://arxiv.org/abs/2502.20639,https://github.com/lemingshen/FedConv,Yes,Varies,Moderate,Continuous Learning
Astra," Astra searches for the efficiency-optimal parallel strategy in both GPU configurations search space (GPU types and GPU numbers) and parallel parameters search space. Then, Astra also provides the solution on heterogeneous GPUs by mathematically modeling the time consumption of heterogeneous training",Optimization,https://arxiv.org/abs/2502.13480,,N/A,High,Fast,Scalable Training and Inference
Hogwild! Inference,"Runs LLM ""workers"" in parallel , allowing them to synchronize via a concurrently-updated attention cache and prompt these workers to decide how best to collaborate",Optimization,https://arxiv.org/abs/2504.06261,https://github.com/eqimp/hogwild_llm,Yes,High,Fast,Scalable Training and Inference
Data Rehearsal,Involves storing a subset of previously encountered data and replaying it during training on new tasks to mitigate catastrophic forgetting in neural networks.,Continual Learning,https://arxiv.org/abs/2306.10181,N/A,N/A,Varies,Moderate,Lifelong Learning
Elastic Weight Consolidation (EWC),"A regularization technique that mitigates catastrophic forgetting by constraining the learning process in neural networks, adding a quadratic penalty term to the loss function to preserve important weights from previous tasks.",Continual Learning,https://arxiv.org/abs/2306.10181,N/A,N/A,Varies,Moderate,Sequential Task Learning
Hierarchical Network Organization,"Organizes neural network architectures in a hierarchical manner to capture multi-scale features, enhancing the model's ability to generalize across tasks and improving performance on complex problems.",Architecture,https://journals.aps.org/pre/abstract/10.1103/PhysRevE.67.026112,N/A,N/A,High,Slow,Complex Problem Solving
Position-Wise Prompts,"A prompt engineering technique where prompts are designed to target specific positions within input sequences, guiding the model's attention and improving performance on tasks requiring focus on particular input segments.",Prompt Engineering,https://arxiv.org/abs/2502.19628,N/A,N/A,Varies,Moderate,Task-Specific Prompting
Center Vector Regularization (CVR),"A regularization method that encourages the representations of data points within the same class to be close to a center vector, enhancing the discriminative power of the model and improving classification performance.",Regularization,https://arxiv.org/abs/2502.21313,N/A,N/A,Varies,Moderate,Classification Tasks
Quantum Circuit Optimization,"Techniques aimed at improving the efficiency and performance of quantum circuits by reducing gate counts, optimizing gate sequences, and minimizing errors, crucial for effective quantum computations.",Quantum Computing,https://www.mdpi.com/2624-960X/7/1/2,N/A,N/A,High,Slow,Quantum Algorithm Design
Encoding Sentences into Quantum Space,"Methods that map classical data, such as sentences, into quantum states, enabling the application of quantum algorithms for tasks like natural language processing and enhancing computational capabilities.",Quantum Computing,https://arxiv.org/abs/2502.20744,N/A,N/A,High,Slow,Quantum Natural Language Processing
Reduction Process and Quantum Gates,"Techniques involving the decomposition of complex quantum operations into simpler gate sequences, facilitating the implementation of quantum algorithms on hardware with limited gate sets and connectivity.",Quantum Computing,https://www.nature.com/articles/s41598-020-67014-5,N/A,N/A,High,Slow,Quantum Algorithm Implementation
Hyperparameters in Quantum Circuits,"The selection and tuning of parameters that define the structure and operation of quantum circuits, impacting their performance, trainability, and suitability for specific tasks.",Quantum Computing,https://onlinelibrary.wiley.com/doi/10.1155/2023/2451990,N/A,N/A,High,Slow,Quantum Circuit Training
Ensembling Zero-Shot and Fine-Tuned Models,"Combines the strengths of zero-shot learning models with fine-tuned models to improve performance across various tasks, leveraging the generalization of zero-shot models and the specificity of fine-tuned models.",Optimization,https://arxiv.org/abs/2109.01903,https://github.com/mlfoundations/wise-ft,Yes,Varies,Moderate,Task Adaptation
Optimal Reinforcement Learning Post-Training,"Applies reinforcement learning techniques to fine-tune LLMs after initial training, optimizing their performance based on specific reward signals and improving task-specific outcomes.",Post-Training,https://arxiv.org/abs/2502.20548,https://github.com/jinpz/q_sharp,Yes,Varies,Moderate,Enhanced Task Performance
Content-Preserving Optimization with Attention Distillation Loss,"Enhances LLMs by preserving the content of original inputs while optimizing attention mechanisms, leading to improved performance without sacrificing the integrity of the input data.",Optimization,https://adasci.org/attention-based-distillation-in-llms-a-comprehensive-overview/,N/A,N/A,Varies,Moderate,Content Preservation
Graph-Driven Dynamic Similarity Grouping,"Utilizes graph-based methods to dynamically group similar data points during training, enhancing the learning process by leveraging the relationships between data instances.",Optimization,https://arxiv.org/abs/2502.20032,https://github.com/AIGNLAI/GDDSG,Yes,Varies,Moderate,Enhanced Learning Dynamics
Adaptivity to Contextual or Structural Demands,"Involves designing LLMs that can adapt their processing strategies based on the context or structure of the input data, improving flexibility and performance across diverse tasks.",Optimization,https://arxiv.org/abs/2502.19078,https://github.com/Oldify/CLADA,Yes,Varies,Moderate,Context-Aware Processing
Tuning Dynamics Based on Singular Value Decomposition,"Applies singular value decomposition techniques to adjust the dynamics of LLMs during training, leading to more efficient learning and better generalization.",Optimization,https://arxiv.org/abs/2403.19067,https://github.com/zstarN70/RLRR,Yes,Varies,Moderate,Efficient Training Dynamics
Backpropagation-Free Optimization,"Explores optimization methods that do not rely on traditional backpropagation, potentially reducing computational overhead and enabling alternative learning paradigms for LLMs.",Optimization,https://arxiv.org/pdf/2402.11592,https://github.com/ZO-Bench/ZO-LLM,Yes,Varies,Moderate,Alternative Learning Methods
Prompt-Based Uncertainty Estimation,"Incorporates uncertainty estimation techniques into prompt-based learning, allowing LLMs to assess the confidence of their responses and improve reliability.",Optimization,https://arxiv.org/abs/2209.06995,https://github.com/yueyu1030/Patron,Yes,Varies,Moderate,Reliable Response Generation
Optimized Training Hyperparameters for Multiscale Byte Language Models,"The Multiscale Byte Language Model is a model-agnostic, hierarchical architecture for causal byte-level language modeling that scales to million-length sequences.",Optimization,https://arxiv.org/abs/2502.14553,https://github.com/ai4sd/multiscale-byte-lm,Yes,Varies,Moderate,Hyperparameter Optimization
Low-Rank Approximation,"Utilizes low-rank matrix approximations to reduce the number of parameters in LLMs, maintaining performance while decreasing computational requirements.",Optimization,https://arxiv.org/abs/2502.20583,https://github.com/efeslab/LiteASR,Yes,Low,Fast,Efficient Model Deployment
Learning from Execution Feedback During Training,"Incorporates feedback from model executions during training to iteratively improve LLM performance, enhancing learning efficiency and outcome quality.",Optimization,https://arxiv.org/abs/2502.20380,N/A,N/A,Varies,Moderate,Iterative Learning Process
Model Dynamics with Simple Cross-Attention Layers,"Enhances LLMs by integrating simple cross-attention layers, improving the interaction between different input representations and boosting model performance.",Architecture,https://tobias-kirschstein.github.io/avat3r/static/Avat3r_paper.pdf,N/A,N/A,Varies,Moderate,Improved Input Interaction
LeMo (Less Token Involvement for More Context Fine-Tuning),"A fine-tuning system that reduces memory consumption by dynamically identifying and excluding redundant tokens during training, enhancing efficiency without compromising model accuracy.",Optimization,https://arxiv.org/abs/2501.09767,N/A,N/A,Low,Fast,Efficient Fine-Tuning
CLoQ (Calibrated LoRA Initialization for Quantized LLMs),"An initialization strategy that enhances fine-tuning of quantized LLMs by minimizing discrepancies between original and quantized models, improving performance especially at ultra-low bit widths.",Quantization,https://arxiv.org/abs/2501.18475,N/A,N/A,Low,Fast,Efficient Fine-Tuning
OPTISHEAR (Efficient and Adaptive Pruning via Evolutionary Optimization),"An evolutionary optimization framework for adaptive pruning of LLMs, optimizing layer-wise sparsity ratios to reduce model size while maintaining performance.",Pruning,https://arxiv.org/abs/2502.10735,N/A,N/A,Varies,Moderate,Model Compression
SparseTransX,"It replaces the core embedding computation with SpMM (Sparse-Dense Matrix Multiplication) kernels. This allows us to unify multiple scatter (and gather) operations as a single operation, reducing training time and memory usage",Optimization,https://arxiv.org/abs/2502.16949,N/A,N/A,Medium,Moderate,Efficient Embedding Computation
Phrasal Paraphrase Relations,"Methods that enhance LLM performance by incorporating phrasal paraphrase relations, improving the model's ability to understand and generate diverse expressions of the same meaning.",Optimization,https://aclanthology.org/D19-1542/,N/A,N/A,Low,Fast,Language Understanding / Paraphrasing
SkipPipe,Partial and Reordered Pipelining Framework for Training LLMs in Heterogeneous Networks,Optimization,https://arxiv.org/abs/2502.19913,https://github.com/gensyn-ai/skippipe,Yes,Medium,Fast,Efficient Model Pipelining
CURLoRA,CURLoRA outperforms standard LoRA in mitigating catastrophic forgetting. It maintains model stability and performance across tasks while significantly reducing the number of trainable parameters.,Fine-Tuning,https://arxiv.org/abs/2408.14572,https://github.com/MNoorFawi/curlora,Yes,Low,Fast,Efficient Finetuning
AMOR: A Recipe for Building Adaptable MOdulaR Knowledge Agents Through Process Feedback,"AMOR builds reasoning logic over a finite state machine (FSM) that solves problems through autonomous executions and transitions over disentangled modules. This allows humans to provide direct feedback to the individual modules, and thus naturally forms process supervision.",Fine-Tuning,https://arxiv.org/abs/2402.01469,https://github.com/JianGuanTHU/AMOR_Agent,Yes,Medium,Moderate,Reasoning over Finite State Machines
Dynamic Low-Rank Sparse Adaptation for Large Language Models,"It seamlessly integrates low-rank adaptation into LLM sparsity within a unified framework, thereby enhancing the performance of sparse LLMs without increasing the inference latency. In particular, LoSA dynamically sparsifies the LoRA outcomes based on the corresponding sparse weights during fine-tuning, thus guaranteeing that the LoRA module can be integrated into the sparse LLMs post-training",,https://arxiv.org/abs/2502.14816,https://github.com/wzhuang-xmu/LoSA,Yes,Low,Fast,Sparse & Efficient Finetuning
Retrieval-Augmented Generation,"It is a technique that enhances the capabilities of generative AI models, like large language models (LLMs), by incorporating information from external knowledge sources",Fine-Tuning,https://arxiv.org/abs/2005.11401,https://huggingface.co/docs/transformers/en/model_doc/rag,Yes,High,Moderate,"Open-Domain QA, Memory-Augmented Tasks"
SIT: Fine-tuning Large Language Models with Sequential Instructions,"It approaches sequential instruction tuning from a task-driven perspective, manually creating interpretable intermediate tasks for multilingual and visual question answering: namely ?translate then predict? and ?caption then answer?",Fine-Tuning,https://arxiv.org/pdf/2403.07794,https://github.com/hanxuhu/SeqIns,Yes,Medium,Moderate,Instruction-Following
FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference,Dynamically adjusts sparse attention patterns and computational budget in real-time to meet the specific requirements of each input and attention head.,Continual Learning,https://arxiv.org/abs/2502.20766,https://github.com/bytedance/FlexPrefill,Yes,Medium,Fast,Context-Aware Sparse Inference
Prompt Templates,"Prompt templates are used during fine-tuning and inference play a crucial role in preserving safety alignment, and proposes the ``Pure Tuning, Safe Testing'' (PTST) strategy -- fine-tune models without a safety prompt, but include it at test time",Post-Training,https://arxiv.org/abs/2402.18540,https://github.com/vfleaking/PTST,Yes,Low,Fast,"Prompt Engineering, Task Instruction"
FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization,An abstractive summarization model that addresses the problem of factuality during pre-training and fine-tuning,Fine-Tuning,https://aclanthology.org/2022.naacl-main.74/,https://github.com/meetdavidwan/factpegasus,Yes,High,Slow,Factual Abstractive Summarization
LoRA-Pro,"A method that enhances LoRA's performance by strategically adjusting the gradients of these low-rank matrices. This adjustment allows the low-rank gradient to more accurately approximate the full fine-tuning gradient, thereby narrowing the performance gap between LoRA and full fine-tuning.",Fine-Tuning,https://openreview.net/forum?id=gTwRMU3lJ5,https://github.com/mrflogs/LoRA-Pro,Yes,Low,Fast,Enhanced Parameter-Efficient Tuning
Retrieval Instead of Fine-tuning,"A method that creates a vectorized database of LoRAs, enabling efficient retrieval and application of model adaptations to new tasks",Fine-Tuning,https://arxiv.org/abs/2410.09908,N/A,N/A,Low,Fast,Retrieval-Augmented Applications
Cicada: A Pipeline-Efficient Approach to Serverless Inference with Decoupled Management,A method to ensure that high-priority inference tasks are completed swiftly by modifying resource allocation,Optimization,https://arxiv.org/abs/2502.20959,N/A,N/A,Medium,Fast,Efficient Inference Task Routing
